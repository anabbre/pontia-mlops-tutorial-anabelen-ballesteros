# ü§ñ Simple ML Training Project

## üìå Descripci√≥n

Repositorio de pr√°ctica para el m√≥dulo de DevOps (M√°ster IA, Cloud Computing y DevOps), de Pontia.tech. El objetivo es implementar un flujo MLOps realista usando **GitHub Actions**, **MLflow** y buenas pr√°cticas de control de versiones: integraci√≥n continua, ramas, PRs, variables/secretos, ejecuci√≥n autom√°tica de pipelines y registro de modelos.

---

## üìÅ Estructura del proyecto

```
‚îú‚îÄ‚îÄ .github/
‚îÇ ‚îî‚îÄ‚îÄ workflows/
‚îÇ ‚îú‚îÄ‚îÄ integration.yml # Pipeline de integraci√≥n continua 
‚îÇ ‚îú‚îÄ‚îÄ build.yml # Pipeline de entrenamiento y registro del modelo
‚îÇ ‚îú‚îÄ‚îÄ deploy.yml # Pipeline de despliegue en Azure Container Instances
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ ‚îî‚îÄ‚îÄ raw/ # Datos sin procesar
‚îÇ ‚îî‚îÄ‚îÄ .gitkeep
‚îÇ
‚îú‚îÄ‚îÄ deployment/
‚îÇ ‚îî‚îÄ‚îÄ app/
‚îÇ ‚îú‚îÄ‚îÄ Dockerfile # Imagen para el despliegue de la API
‚îÇ ‚îî‚îÄ‚îÄ requirements.txt # Dependencias de la API
‚îÇ
‚îú‚îÄ‚îÄ mlartifacts/ # Artefactos generados en el flujo (modelo, registros...)
‚îú‚îÄ‚îÄ mlruns/ # Directorio de MLflow para seguimiento de experimentos
‚îÇ
‚îú‚îÄ‚îÄ model_tests/
‚îÇ ‚îî‚îÄ‚îÄ test_model.py # Tests autom√°ticos para el modelo
‚îÇ
‚îú‚îÄ‚îÄ models/ # Modelos exportados
‚îÇ ‚îî‚îÄ‚îÄ .gitkeep
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ ‚îú‚îÄ‚îÄ query_model.py # Script para consultar el modelo v√≠a API
‚îÇ ‚îî‚îÄ‚îÄ register_model.py # Script para registrar el modelo en MLflow
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ ‚îú‚îÄ‚îÄ init.py
‚îÇ ‚îú‚îÄ‚îÄ data_loader.py # Carga y preprocesamiento de datos
‚îÇ ‚îú‚îÄ‚îÄ evaluate.py # Evaluaci√≥n del modelo
‚îÇ ‚îú‚îÄ‚îÄ main.py # Entrenamiento y guardado del modelo
‚îÇ ‚îú‚îÄ‚îÄ model.py # Definici√≥n del modelo
‚îÇ ‚îú‚îÄ‚îÄ run_id.txt # ID del √∫ltimo experimento exitoso
‚îÇ ‚îî‚îÄ‚îÄ training.log # Logs de entrenamiento
‚îÇ
‚îú‚îÄ‚îÄ unit_tests/
‚îÇ ‚îú‚îÄ‚îÄ init.py
‚îÇ ‚îú‚îÄ‚îÄ test_data_loader.py # Test para la carga de datos
‚îÇ ‚îú‚îÄ‚îÄ test_evaluate.py # Test de evaluaci√≥n del modelo
‚îÇ ‚îî‚îÄ‚îÄ test_model.py # Test unitario del modelo
‚îÇ
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt # Dependencias generales del proyecto
‚îî‚îÄ‚îÄ .gitignore
```

### üóÇÔ∏è Descripci√≥n de carpetas

- **.github/workflows/**: Contiene los tres workflows de CI/CD (`build.yml`, `integration.yml`, `deploy.yml`).
- **data/raw/**: Datos originales del dataset.
- **deployment/app/**: C√≥digo necesario para desplegar la API en Azure Container Instances.
- **mlartifacts/** y **mlruns/**: Directorios para el seguimiento y almacenamiento de modelos y m√©tricas por MLflow.
- **model_tests/**: Script para validar el modelo despu√©s del entrenamiento.
- **models/**: Carpeta vac√≠a reservada para versiones del modelo exportadas.
- **scripts/**: Scripts complementarios para registrar y consultar el modelo v√≠a API.
- **src/**: C√≥digo principal del pipeline de entrenamiento, evaluaci√≥n y definici√≥n del modelo.
- **unit_tests/**: Tests unitarios para comprobar la funcionalidad de los distintos m√≥dulos (`data_loader`, `evaluate`, `model`).
- **requirements.txt**: Fichero con todas las dependencias necesarias para instalar y ejecutar el proyecto.

---

## üîß Preparaci√≥n del Repositorio

1. Crear nuevo repositorio con el nombre `pontia-mlops-tutorial-nombre-apellido`.
2. Clonar el repo original de referencia: `https://github.com/merlinkd/pontia-mlops-tutorial`.
3. Copiar el contenido del repositorio base al nuevo repositorio personal.
4. A√±adir `.gitignore`, `requirements.txt`, y actualizar estructura de carpetas.
5. Crear el archivo `requirements.txt` en la ra√≠z del proyecto con las dependencias b√°sicas del modelo:
- scikit-learn
- pandas
- joblib
- mlflow
6. Configurar los **Secrets** y **Variables** en GitHub > Settings > Secrets and variables > Actions:
   - Secret: `AZURE_STORAGE_CONNECTION_STRING`
   - Variables: `MLFLOW_URL`, `EXPERIMENT_NAME`, `MODEL_NAME`
7. Ejecutar `main.py` localmente y verificar la creaci√≥n de registros en `mlruns/`.
8. Subir los cambios a GitHub (`push` a la rama `main` o a la rama correspondiente).


## üîÅ Flujo de trabajo seguido CI/CD

### üìå 1. **Pipeline de Integraci√≥n Continua**: `integration.yml`

Esta pipeline verifica que el repositorio est√© correctamente estructurado antes de integrar cambios a `main`.

üìÅ El archivo `.github/workflows/integration.yml` incluye:

- `workflow_dispatch`: permite ejecutar la pipeline manualmente desde GitHub Actions.
- Versi√≥n de Python actualizada a 3.10.
- Instalaci√≥n de dependencias desde `requirements.txt`.
- Se ejecuta autom√°ticamente en **push** o **pull request** hacia la rama `integration`.
- Realiza validaciones b√°sicas:
  - Que exista el archivo `main.py`.
  - Que se puedan instalar correctamente las dependencias.
- Se a√±adi√≥ `continue-on-error: true` e `if: always` para que la pipeline contin√∫e incluso si fallan los tests.
- Requiere PR para merge a `main` con revisi√≥n de compa√±ero/a (`Looks good to me`).

üí° **Consejo**: Esta pipeline es clave porque **bloquea los merges directos** a `main` si algo falla. Obliga a trabajar con ramas y revisiones, promoviendo buenas pr√°cticas en integraci√≥n continua.

> üìù **Nota:** Inicialmente tambi√©n se hab√≠a subido la pipeline `deploy.yml`, pero fue eliminada temporalmente por errores de ejecuci√≥n. Se re-subir√° m√°s adelante otra versi√≥n una vez solucionados los conflictos.

---

### üîê Configuraci√≥n de GitHub: Rulesets, Secrets y Variables

Para asegurar un correcto funcionamiento del flujo CI/CD y proteger la rama principal, se configur√≥ el repositorio en GitHub con los siguientes pasos:

#### üõ°Ô∏è Ruleset para la rama `main`

Se a√±adi√≥ un conjunto de reglas (ruleset) en GitHub para proteger la rama `main`, incluyendo:

1. **Target**: `main`.
2. **Restricciones aplicadas**:
   - ‚ùå No permitir eliminaciones de la rama.
   - üîí Bloquear `force push`.
   - ‚úÖ Requerir que los **checks de estado pasen** antes de permitir merge.
   - üîÑ Exigir que las ramas est√©n actualizadas con respecto a `main` antes de hacer merge.
   - ‚úîÔ∏è Especificar qu√© check de estado se requiere (por ejemplo, el job de la pipeline `integration.yml`).

> üìù Esto asegura que no se puedan hacer merges si la pipeline de integraci√≥n no pasa correctamente.

---

#### üîë Creaci√≥n de Secrets y Variables del Repositorio

Se configuraron los siguientes secretos y variables desde **Settings > Secrets and variables > Actions**:

##### üîê Secret:

- `AZURE_STORAGE_CONNECTION_STRING`: Contiene el string de conexi√≥n necesario para almacenar modelos en Azure Blob Storage.

##### ‚öôÔ∏è Variables:

- `EXPERIMENT_NAME`: Nombre del experimento en MLflow (ej. `nombre-apellido-income`).
- `MODEL_NAME`: Nombre del modelo en MLflow.
- `MLFLOW_URL`: URL del servidor de MLflow (ej. `http://mlflow-servidor:5000`).

---

#### üîÑ Verificaci√≥n de configuraci√≥n

Para validar que la configuraci√≥n funciona correctamente:

1. Se cre√≥ un **pull request (PR)** desde la rama `integration` hacia `main`, con un cambio trivial.
2. El ruleset bloque√≥ el merge autom√°ticamente porque no se cumpl√≠an los checks requeridos.
3. Se valid√≥ que la **pipeline `integration.yml`** se ejecutaba correctamente como verificaci√≥n del estado del repositorio.

> üí° **Consejo:** Esta configuraci√≥n es clave para garantizar un flujo de trabajo profesional, donde solo se permiten cambios en `main` tras validaciones y revisiones.

---

### üèóÔ∏è 2. **Pipeline de Construcci√≥n del Modelo**: `build.yml`

Esta pipeline permite entrenar y registrar el modelo autom√°ticamente en MLflow usando GitHub Actions.

üîß El archivo `.github/workflows/build.yml` incluye:

- `workflow_dispatch`: permite ejecutar la pipeline manualmente desde GitHub Actions.
- Tambi√©n se ejecuta autom√°ticamente al hacer **`push`** sobre la rama `main`.
- Versi√≥n de Python configurada a 3.10.
- Instalaci√≥n de dependencias desde `requirements.txt`.
- Descarga del dataset desde la UCI.
- Entrenamiento del modelo mediante ejecuci√≥n de `main.py`.
- Obtenci√≥n y exportaci√≥n del `run_id` generado en el entrenamiento para poder registrar el modelo.
- Registro del modelo en MLflow mediante el script `register_model.py`.
- Se agregaron variables de entorno con los valores necesarios obtenidos desde los **Secrets** y **Repository Variables**.

üìÑ El archivo `register_model.py` fue modificado para que tome los valores desde el entorno:

```python
run_id = os.getenv('RUN_ID', 'run_id not found')
model_name = os.getenv("MODEL_NAME", "no_name")
```

üß™ Se a√±adi√≥ un paso de testeo b√°sico para validar el modelo entrenado:

```yaml
- name: Run model tests
  run: python model_tests/test_model.pyv
```

üìÅ Estos tests se ubican dentro de la carpeta `model_tests/` e incluyen validaciones como:

- Que el modelo se cargue correctamente.
- Que las predicciones tengan forma esperada.
- Que las predicciones est√©n en el rango esperado.
- Que la precisi√≥n (accuracy) supere el umbral m√≠nimo (ej. 0.80).

---
### üîß 3. **Pipeline de Despliegue de Modelo**: `deploy.yml`

Esta pipeline permite desplegar autom√°ticamente el modelo entrenado en un contenedor de Azure, incluyendo la configuraci√≥n necesaria y el registro del modelo con sus artefactos de preprocesado.

üìÅ El archivo `.github/workflows/deploy.yml` realiza los siguientes pasos:

- Define un `workflow_dispatch` para permitir la ejecuci√≥n manual desde GitHub Actions.
- Usa como base el fichero `deploy.yml` actualizado proporcionado por el profesorado, con errores anteriores corregidos.
- Configura el entorno con variables y secretos previamente definidos:
  - `AZURE_CREDENTIALS`, `ACR_USERNAME`, `ACR_PASSWORD`, `ACR_NAME`, `AZURE_RESOURCE_GROUP`
  - `MODEL_NAME`, `MODEL_ALIAS`, `AZURE_CONTAINER_NAME`, `IMAGE_NAME`, `AZURE_REGION`
- Utiliza los valores de entorno definidos para desplegar el contenedor con la API del modelo.
- El modelo se registra en MLflow junto a los artefactos de preprocesamiento:
  - `scaler.pkl` y `encoders.pkl` se loguean mediante `mlflow.log_artifact`.

‚úÖ Antes de lanzar esta pipeline, se corrigieron:

- El `Dockerfile`, incluyendo los comandos para instalar las dependencias:

```
COPY requirements.txt /code/
RUN pip install --upgrade pip
RUN pip install --no-cache-dir -r requirements.txt
```

- El archivo `register_model.py`, cambiando `{model_artifact_path}` por `model` para evitar errores de URI en el registro.
- Se incluy√≥ `query_model.py` entregado por el profesor.

üß™ Al ejecutar la pipeline desde el branch `deploy`, se valida que:

- El contenedor con el modelo se lanza correctamente.
- El modelo queda registrado junto a los artefactos (modelo, scaler, encoders).
- La ejecuci√≥n se ve reflejada correctamente en MLflow.

üìù Finalmente:

- Se ejecuta manualmente la pipeline "Deploy Model" desde el branch `deploy`.
- Se revisan los logs si es necesario con:

```bash
az container logs --resource-group mlflow-rg --name model-api-NOMBRE
```

- Se solicita revisi√≥n a un/a compa√±ero/a, quien debe dejar un comentario como "Looks good to me" antes de hacer merge a `main`.

---

## üìé Anexo

Este proyecto ha seguido buenas pr√°cticas DevOps ‚úÖ:

- üß© Uso de ramas `integration`, `build`, `deploy`.

- üîÅ Validaci√≥n por pipelines antes del merge.

![alt text](img/image-5.png)
![alt text](img/image-6.png)

- üì¶ Registro de modelos y artefactos en MLflow.

![alt text](img/image-1.png)

- ü§ñ Automatizaci√≥n mediante GitHub Actions.m

![alt text](img/image-4.png)

- üöÄ Despliegue autom√°tico a Azure.

![alt text](img/image.png)

üì¨ **Evidencia del funcionamiento**: API disponible + predicciones consultables con script local (`query_model.py`).

![alt text](img/image-3.png)

![alt text](img/image-2.png)
---

## üìÑ Archivo adicional: problemas_resueltos.md

Se incluye el archivo `problemas_resueltos.md` con un resumen de los problemas encontrados durante la implementaci√≥n y c√≥mo se resolvieron. 

---

## üë• Autora del proyecto

- **Nombre y Apellido**: Ana Bel√©n Ballesteros  
  - M√°ster en IA, Cloud Computing y DevOps

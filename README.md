# Simple ML Training Project

## DescripciÃ³n

Repositorio de prÃ¡ctica para el mÃ³dulo de DevOps (MÃ¡ster IA, Cloud Computing y DevOps), siguiendo el tutorial de PontIA. El objetivo es implementar un flujo MLOps realista usando **GitHub Actions**, **MLflow** y buenas prÃ¡cticas de control de versiones: integraciÃ³n continua, ramas, PRs, variables/secretos, ejecuciÃ³n automÃ¡tica de pipelines y registro de modelos.

---

## Estructura del proyecto

```
â”œâ”€â”€ .github/
â”‚ â””â”€â”€ workflows/
â”‚ â”œâ”€â”€ build.yml # Pipeline de build y training del modelo
â”‚ â””â”€â”€ integration.yml # Pipeline de integraciÃ³n continua (primer paso)
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ main.py
â”‚ â”œâ”€â”€ data_loader.py
â”‚ â”œâ”€â”€ evaluate.py
â”‚ â””â”€â”€ model.py
â”œâ”€â”€ model_tests/
â”‚ â””â”€â”€ test_model.py
â”œâ”€â”€ scripts/
â”‚ â””â”€â”€ register_model.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

- **.github/workflows/**: DefiniciÃ³n de los pipelines de CI/CD.
- **src/**: CÃ³digo principal del pipeline de ML.
- **model_tests/**: Tests automatizados para validaciÃ³n del modelo.
- **scripts/**: Scripts auxiliares, como el registro del modelo en MLflow.
- **requirements.txt**: Dependencias del proyecto.

---

## ğŸ”§ PreparaciÃ³n del Repositorio

1. Crear nuevo repositorio con el nombre `pontia-mlops-tutorial-nombre-apellido`.
2. Clonar el repo original de referencia: `pontia-mlops-tutorial`.
3. Copiar el contenido al nuevo repositorio.
4. AÃ±adir `.gitignore`, `requirements.txt`, y actualizar estructura de carpetas.
5. Configurar **secrets** en GitHub:
   - `AZURE_STORAGE_CONNECTION_STRING`
   - `MLFLOW_URL`
   - `EXPERIMENT_NAME`
   - `MODEL_NAME`
6. Probar ejecuciÃ³n local de `main.py` para entrenar y guardar modelo.
7. Subir cambios a GitHub (`push` a `main`).

## ğŸ” Flujo de trabajo seguido (paso a paso)

### 1. **Pipeline de IntegraciÃ³n Continua**: `integration.yml`

Esta pipeline verifica que el repositorio estÃ© correctamente estructurado antes de integrar cambios a `main`.

ğŸ“„ El archivo `.github/workflows/integration.yml` incluye:

- `workflow_dispatch`: permite ejecutar la pipeline manualmente desde GitHub Actions.
- Python 3.10.
- InstalaciÃ³n de dependencias desde `requirements.txt`.
- Se ejecuta automÃ¡ticamente en **push** o **pull request** a la rama `integration`.
- Realiza validaciones bÃ¡sicas:
  - Que exista el archivo `main.py`.
  - Que se puedan instalar las dependencias.
- AÃ±ade `continue-on-error: true` e `if: always` para seguir la pipeline aunque fallen los tests.
- Al crear una PR desde `integration` a `main`, se solicita revisiÃ³n y se valida con comentarios tipo: `Looks good to me`.

ğŸ’¡ **Consejo**: Esta pipeline es clave porque **bloquea los merges directos** a `main` si algo falla. Obliga a trabajar con ramas y revisiones.

---

### 2. **Pipeline de Build y Registro de Modelo**: `build.yml`

âš™ï¸ Esta pipeline entrena y registra el modelo en MLflow automÃ¡ticamente desde GitHub Actions.

ğŸ“„ El archivo `.github/workflows/build.yml`:

- Instala dependencias.
- Descarga datasets.
- Llama al script `main.py` para entrenar el modelo.
- Usa `register_model.py` para registrar el modelo en MLflow.
- Usa `run_id` como variable.
- Sube artefactos (`scaler.pkl`, `encoders.pkl`, etc.).
- Corre tests (`test_model.py`).
- Solo se ejecuta con push a la rama `main`.
- VerificaciÃ³n final en MLflow:
  - Registro correcto del modelo.
  - ApariciÃ³n de artefactos (modelo, scaler, encoder).

---
### 3. **Despliegue del modelo**: `deploy.yml` (pendiente de implementar)

- Crea rama `deploy` y aÃ±ade un archivo `deploy.yml` dummy.
- AÃ±adir secretos adicionales:
  - `AZURE_CREDENTIALS`, `ACR_USERNAME`, `ACR_PASSWORD`, `ACR_NAME`, `AZURE_RESOURCE_GROUP`
- Variables:
  - `MODEL_NAME`, `MODEL_ALIAS`, `AZURE_CONTAINER_NAME`, `IMAGE_NAME`, `AZURE_REGION`
- Copiar carpeta `deployment/` al root.
- Completar el `Dockerfile`.
- Corregir el error en `register_model.py` reemplazando `model artifact path` por `"model"`.
- Crear PR desde `deploy` a `main`.

---

## â–¶ï¸ EjecuciÃ³n

- Ejecutar `Build Model` desde la rama `deploy`.
- Verificar que se suben correctamente los artefactos en MLflow.
- Ejecutar `Deploy Model` y validar el despliegue exitoso (puede tardar unos 15 min).

ğŸ“‹ Comando para inspeccionar logs del contenedor en Azure:
```
az container logs --resource-group mlflow-rg --name model-api-UCI
```
---

## Problemas habituales y cÃ³mo los he resuelto

* âŒ Error ModuleNotFoundError: No module named 'src'
SucedÃ­a al ejecutar la pipeline en GitHub Actions (pero no siempre en local).

* SoluciÃ³n: Ejecutar SIEMPRE los scripts desde la raÃ­z y llamar explÃ­citamente a los scripts con el path completo:
```
python src/main.py
```
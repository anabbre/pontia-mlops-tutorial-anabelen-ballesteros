# ğŸ¤– Simple ML Training Project

## ğŸ“Œ DescripciÃ³n

Repositorio de prÃ¡ctica para el mÃ³dulo de DevOps (MÃ¡ster IA, Cloud Computing y DevOps), siguiendo el tutorial de PontIA. El objetivo es implementar un flujo MLOps realista usando **GitHub Actions**, **MLflow** y buenas prÃ¡cticas de control de versiones: integraciÃ³n continua, ramas, PRs, variables/secretos, ejecuciÃ³n automÃ¡tica de pipelines y registro de modelos.

---

## ğŸ“ Estructura del proyecto

```
â”œâ”€â”€ .github/
â”‚ â””â”€â”€ workflows/
â”‚ â”œâ”€â”€ integration.yml # Pipeline de integraciÃ³n continua 
â”‚ â”œâ”€â”€ build.yml # Pipeline de entrenamiento y registro del modelo
â”‚ â”œâ”€â”€ deploy.yml # Pipeline de despliegue en Azure Container Instances
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ raw/ # Datos sin procesar
â”‚ â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ deployment/
â”‚ â””â”€â”€ app/
â”‚ â”œâ”€â”€ Dockerfile # Imagen para el despliegue de la API
â”‚ â””â”€â”€ requirements.txt # Dependencias de la API
â”‚
â”œâ”€â”€ mlartifacts/ # Artefactos generados en el flujo (modelo, registros...)
â”œâ”€â”€ mlruns/ # Directorio de MLflow para seguimiento de experimentos
â”‚
â”œâ”€â”€ model_tests/
â”‚ â””â”€â”€ test_model.py # Tests automÃ¡ticos para el modelo
â”‚
â”œâ”€â”€ models/ # Modelos exportados
â”‚ â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ query_model.py # Script para consultar el modelo vÃ­a API
â”‚ â””â”€â”€ register_model.py # Script para registrar el modelo en MLflow
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ data_loader.py # Carga y preprocesamiento de datos
â”‚ â”œâ”€â”€ evaluate.py # EvaluaciÃ³n del modelo
â”‚ â”œâ”€â”€ main.py # Entrenamiento y guardado del modelo
â”‚ â”œâ”€â”€ model.py # DefiniciÃ³n del modelo
â”‚ â”œâ”€â”€ run_id.txt # ID del Ãºltimo experimento exitoso
â”‚ â””â”€â”€ training.log # Logs de entrenamiento
â”‚
â”œâ”€â”€ unit_tests/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ test_data_loader.py # Test para la carga de datos
â”‚ â”œâ”€â”€ test_evaluate.py # Test de evaluaciÃ³n del modelo
â”‚ â””â”€â”€ test_model.py # Test unitario del modelo
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt # Dependencias generales del proyecto
â””â”€â”€ .gitignore
```

### ğŸ—‚ï¸ DescripciÃ³n de carpetas

- **.github/workflows/**: Contiene los tres workflows de CI/CD (`build.yml`, `integration.yml`, `deploy.yml`).
- **data/raw/**: Datos originales del dataset.
- **deployment/app/**: CÃ³digo necesario para desplegar la API en Azure Container Instances.
- **mlartifacts/** y **mlruns/**: Directorios para el seguimiento y almacenamiento de modelos y mÃ©tricas por MLflow.
- **model_tests/**: Script para validar el modelo despuÃ©s del entrenamiento.
- **models/**: Carpeta vacÃ­a reservada para versiones del modelo exportadas.
- **scripts/**: Scripts complementarios para registrar y consultar el modelo vÃ­a API.
- **src/**: CÃ³digo principal del pipeline de entrenamiento, evaluaciÃ³n y definiciÃ³n del modelo.
- **unit_tests/**: Tests unitarios para comprobar la funcionalidad de los distintos mÃ³dulos (`data_loader`, `evaluate`, `model`).
- **requirements.txt**: Fichero con todas las dependencias necesarias para instalar y ejecutar el proyecto.

---

## ğŸ”§ PreparaciÃ³n del Repositorio

1. Crear nuevo repositorio con el nombre `pontia-mlops-tutorial-nombre-apellido`.
2. Clonar el repo original de referencia: `https://github.com/merlinkd/pontia-mlops-tutorial`.
3. Copiar el contenido del repositorio base al nuevo repositorio personal.
4. AÃ±adir `.gitignore`, `requirements.txt`, y actualizar estructura de carpetas.
5. Crear el archivo `requirements.txt` en la raÃ­z del proyecto con las dependencias bÃ¡sicas del modelo:
- scikit-learn
- pandas
- joblib
- mlflow
6. Configurar los **Secrets** y **Variables** en GitHub > Settings > Secrets and variables > Actions:
   - Secret: `AZURE_STORAGE_CONNECTION_STRING`
   - Variables: `MLFLOW_URL`, `EXPERIMENT_NAME`, `MODEL_NAME`
7. Ejecutar `main.py` localmente y verificar la creaciÃ³n de registros en `mlruns/`.
8. Subir los cambios a GitHub (`push` a la rama `main` o a la rama correspondiente).


## ğŸ” Flujo de trabajo seguido CI/CD

### ğŸ“Œ 1. **Pipeline de IntegraciÃ³n Continua**: `integration.yml`

Esta pipeline verifica que el repositorio estÃ© correctamente estructurado antes de integrar cambios a `main`.

ğŸ“ El archivo `.github/workflows/integration.yml` incluye:

- `workflow_dispatch`: permite ejecutar la pipeline manualmente desde GitHub Actions.
- VersiÃ³n de Python actualizada a 3.10.
- InstalaciÃ³n de dependencias desde `requirements.txt`.
- Se ejecuta automÃ¡ticamente en **push** o **pull request** hacia la rama `integration`.
- Realiza validaciones bÃ¡sicas:
  - Que exista el archivo `main.py`.
  - Que se puedan instalar correctamente las dependencias.
- Se aÃ±adiÃ³ `continue-on-error: true` e `if: always` para que la pipeline continÃºe incluso si fallan los tests.
- Requiere PR para merge a `main` con revisiÃ³n de compaÃ±ero/a (`Looks good to me`).

ğŸ’¡ **Consejo**: Esta pipeline es clave porque **bloquea los merges directos** a `main` si algo falla. Obliga a trabajar con ramas y revisiones, promoviendo buenas prÃ¡cticas en integraciÃ³n continua.

> ğŸ“ **Nota:** Inicialmente tambiÃ©n se habÃ­a subido la pipeline `deploy.yml`, pero fue eliminada temporalmente por errores de ejecuciÃ³n. Se re-subirÃ¡ mÃ¡s adelante otra versiÃ³n una vez solucionados los conflictos.

---

### ğŸ” ConfiguraciÃ³n de GitHub: Rulesets, Secrets y Variables

Para asegurar un correcto funcionamiento del flujo CI/CD y proteger la rama principal, se configurÃ³ el repositorio en GitHub con los siguientes pasos:

#### ğŸ›¡ï¸ Ruleset para la rama `main`

Se aÃ±adiÃ³ un conjunto de reglas (ruleset) en GitHub para proteger la rama `main`, incluyendo:

1. **Target**: `main`.
2. **Restricciones aplicadas**:
   - âŒ No permitir eliminaciones de la rama.
   - ğŸ”’ Bloquear `force push`.
   - âœ… Requerir que los **checks de estado pasen** antes de permitir merge.
   - ğŸ”„ Exigir que las ramas estÃ©n actualizadas con respecto a `main` antes de hacer merge.
   - âœ”ï¸ Especificar quÃ© check de estado se requiere (por ejemplo, el job de la pipeline `integration.yml`).

> ğŸ“ Esto asegura que no se puedan hacer merges si la pipeline de integraciÃ³n no pasa correctamente.

---

#### ğŸ”‘ CreaciÃ³n de Secrets y Variables del Repositorio

Se configuraron los siguientes secretos y variables desde **Settings > Secrets and variables > Actions**:

##### ğŸ” Secret:

- `AZURE_STORAGE_CONNECTION_STRING`: Contiene el string de conexiÃ³n necesario para almacenar modelos en Azure Blob Storage.

##### âš™ï¸ Variables:

- `EXPERIMENT_NAME`: Nombre del experimento en MLflow (ej. `nombre-apellido-income`).
- `MODEL_NAME`: Nombre del modelo en MLflow.
- `MLFLOW_URL`: URL del servidor de MLflow (ej. `http://mlflow-servidor:5000`).

---

#### ğŸ”„ VerificaciÃ³n de configuraciÃ³n

Para validar que la configuraciÃ³n funciona correctamente:

1. Se creÃ³ un **pull request (PR)** desde la rama `integration` hacia `main`, con un cambio trivial.
2. El ruleset bloqueÃ³ el merge automÃ¡ticamente porque no se cumplÃ­an los checks requeridos.
3. Se validÃ³ que la **pipeline `integration.yml`** se ejecutaba correctamente como verificaciÃ³n del estado del repositorio.

> ğŸ’¡ **Consejo:** Esta configuraciÃ³n es clave para garantizar un flujo de trabajo profesional, donde solo se permiten cambios en `main` tras validaciones y revisiones.

---

### 2. ğŸ—ï¸ **Pipeline de ConstrucciÃ³n del Modelo**: `build.yml`

Esta pipeline permite entrenar y registrar el modelo automÃ¡ticamente en MLflow usando GitHub Actions.

ğŸ”§ El archivo `.github/workflows/build.yml` incluye:

- `workflow_dispatch`: permite ejecutar la pipeline manualmente desde GitHub Actions.
- TambiÃ©n se ejecuta automÃ¡ticamente al hacer **`push`** sobre la rama `main`.
- VersiÃ³n de Python configurada a 3.10.
- InstalaciÃ³n de dependencias desde `requirements.txt`.
- Descarga del dataset desde la UCI.
- Entrenamiento del modelo mediante ejecuciÃ³n de `main.py`.
- ObtenciÃ³n y exportaciÃ³n del `run_id` generado en el entrenamiento para poder registrar el modelo.
- Registro del modelo en MLflow mediante el script `register_model.py`.
- Se agregaron variables de entorno con los valores necesarios obtenidos desde los **Secrets** y **Repository Variables**.

ğŸ“„ El archivo `register_model.py` fue modificado para que tome los valores desde el entorno:

```python
run_id = os.getenv('RUN_ID', 'run_id not found')
model_name = os.getenv("MODEL_NAME", "no_name")
```

ğŸ§ª Se aÃ±adiÃ³ un paso de testeo bÃ¡sico para validar el modelo entrenado:

```yaml
- name: Run model tests
  run: python model_tests/test_model.pyv
```

ğŸ“ Estos tests se ubican dentro de la carpeta `model_tests/` e incluyen validaciones como:

- Que el modelo se cargue correctamente.
- Que las predicciones tengan forma esperada.
- Que las predicciones estÃ©n en el rango esperado.
- Que la precisiÃ³n (accuracy) supere el umbral mÃ­nimo (ej. 0.80).

---
### ğŸ”§ 3. **Pipeline de Despliegue de Modelo**: `deploy.yml`

Esta pipeline permite desplegar automÃ¡ticamente el modelo entrenado en un contenedor de Azure, incluyendo la configuraciÃ³n necesaria y el registro del modelo con sus artefactos de preprocesado.

ğŸ“ El archivo `.github/workflows/deploy.yml` realiza los siguientes pasos:

- Define un `workflow_dispatch` para permitir la ejecuciÃ³n manual desde GitHub Actions.
- Usa como base el fichero `deploy.yml` actualizado proporcionado por el profesorado, con errores anteriores corregidos.
- Configura el entorno con variables y secretos previamente definidos:
  - `AZURE_CREDENTIALS`, `ACR_USERNAME`, `ACR_PASSWORD`, `ACR_NAME`, `AZURE_RESOURCE_GROUP`
  - `MODEL_NAME`, `MODEL_ALIAS`, `AZURE_CONTAINER_NAME`, `IMAGE_NAME`, `AZURE_REGION`
- Utiliza los valores de entorno definidos para desplegar el contenedor con la API del modelo.
- El modelo se registra en MLflow junto a los artefactos de preprocesamiento:
  - `scaler.pkl` y `encoders.pkl` se loguean mediante `mlflow.log_artifact`.

âœ… Antes de lanzar esta pipeline, se corrigieron:

- El `Dockerfile`, incluyendo los comandos para instalar las dependencias:

```
COPY requirements.txt /code/
RUN pip install --upgrade pip
RUN pip install --no-cache-dir -r requirements.txt
```

- El archivo `register_model.py`, cambiando `{model_artifact_path}` por `model` para evitar errores de URI en el registro.
- Se incluyÃ³ `query_model.py` entregado por el profesor.

ğŸ§ª Al ejecutar la pipeline desde el branch `deploy`, se valida que:

- El contenedor con el modelo se lanza correctamente.
- El modelo queda registrado junto a los artefactos (modelo, scaler, encoders).
- La ejecuciÃ³n se ve reflejada correctamente en MLflow.

ğŸ“ Finalmente:

- Se ejecuta manualmente la pipeline "Deploy Model" desde el branch `deploy`.
- Se revisan los logs si es necesario con:

```bash
az container logs --resource-group mlflow-rg --name model-api-NOMBRE
```

- Se solicita revisiÃ³n a un/a compaÃ±ero/a, quien debe dejar un comentario como "Looks good to me" antes de hacer merge a `main`.

---

## ğŸ“ Anexo

Este proyecto ha seguido buenas prÃ¡cticas DevOps âœ…:

- ğŸ§© Uso de ramas `integration`, `build`, `deploy`.

- ğŸ” ValidaciÃ³n por pipelines antes del merge.

![alt text](img/image-5.png)
![alt text](img/image-6.png)

- ğŸ“¦ Registro de modelos y artefactos en MLflow.

![alt text](img/image-1.png)

- ğŸ¤– AutomatizaciÃ³n mediante GitHub Actions.m

![alt text](img/image-4.png)

- ğŸš€ Despliegue automÃ¡tico a Azure.

![alt text](img/image.png)

ğŸ“¬ **Evidencia del funcionamiento**: API disponible + predicciones consultables con script local (`query_model.py`).

![alt text](img/image-3.png)

![alt text](img/image-2.png)
---

## ğŸ“„ Archivo adicional: problemas_resueltos.md

Se incluye el archivo `problemas_resueltos.md` con un resumen de los problemas encontrados durante la implementaciÃ³n y cÃ³mo se resolvieron. 

---

## ğŸ‘¥ Autora del proyecto

- **Nombre y Apellido**: Ana BelÃ©n Ballesteros  
  - MÃ¡ster en IA, Cloud Computing y DevOps
